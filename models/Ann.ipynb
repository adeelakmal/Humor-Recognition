{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Data.csv')\n",
    "# Selects the Category with the highest value for each row\n",
    "dataset['Max'] = dataset[['affiliative', 'selfenhancing','agressive', 'selfdefeating']].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and preprocessing the dataset\n",
    "encoder = OneHotEncoder()\n",
    "X = dataset.iloc[:, 0:32]\n",
    "imputer = SimpleImputer(missing_values=-1, strategy='mean')\n",
    "Y= encoder.fit_transform(dataset[['Max']])\n",
    "Y = Y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 5, 3, ..., 4, 4, 4],\n",
       "       [2, 2, 4, ..., 3, 2, 4],\n",
       "       [1, 4, 4, ..., 5, 5, 1],\n",
       "       ...,\n",
       "       [1, 3, 4, ..., 5, 1, 1],\n",
       "       [1, 5, 3, ..., 3, 4, 4],\n",
       "       [1, 4, 3, ..., 3, 1, 5]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=X.to_numpy()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0237853 ,  1.52499633, -0.05399147, ...,  0.04785243,\n",
       "         0.92171733,  0.91989192],\n",
       "       [-0.0237853 , -1.22900548,  0.80187331, ..., -0.84261886,\n",
       "        -0.59996066,  0.91989192],\n",
       "       [-0.94924965,  0.60699573,  0.80187331, ...,  0.93832371,\n",
       "         1.68255633, -1.50794205],\n",
       "       ...,\n",
       "       [-0.94924965, -0.31100488,  0.80187331, ...,  0.93832371,\n",
       "        -1.36079965, -1.50794205],\n",
       "       [-0.94924965,  1.52499633, -0.05399147, ..., -0.84261886,\n",
       "         0.92171733,  0.91989192],\n",
       "       [-0.94924965,  0.60699573, -0.05399147, ..., -0.84261886,\n",
       "        -1.36079965,  1.72916991]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                1650      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 25)                1275      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 104       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,029\n",
      "Trainable params: 3,029\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building the network\n",
    "ann = tf.keras.models.Sequential()\n",
    "ann.add(tf.keras.layers.Dense(units=50, activation='sigmoid', input_shape=X_train[0].shape))\n",
    "ann.add(tf.keras.layers.Dense(units=25, activation='sigmoid'))\n",
    "ann.add(tf.keras.layers.Dense(units=4, activation=\"sigmoid\"))\n",
    "ann.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27/27 [==============================] - 2s 4ms/step - loss: 0.6060 - accuracy: 0.7664\n",
      "Epoch 2/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7664\n",
      "Epoch 3/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3754 - accuracy: 0.7664\n",
      "Epoch 4/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.3416 - accuracy: 0.7664\n",
      "Epoch 5/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3217 - accuracy: 0.7664\n",
      "Epoch 6/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3055 - accuracy: 0.7664\n",
      "Epoch 7/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2900 - accuracy: 0.7664\n",
      "Epoch 8/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.7664\n",
      "Epoch 9/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2578 - accuracy: 0.7675\n",
      "Epoch 10/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2418 - accuracy: 0.7804\n",
      "Epoch 11/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2273 - accuracy: 0.7956\n",
      "Epoch 12/100\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.2144 - accuracy: 0.8154\n",
      "Epoch 13/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.2033 - accuracy: 0.8294\n",
      "Epoch 14/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1938 - accuracy: 0.8470\n",
      "Epoch 15/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1859 - accuracy: 0.8563\n",
      "Epoch 16/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1787 - accuracy: 0.8645\n",
      "Epoch 17/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1728 - accuracy: 0.8692\n",
      "Epoch 18/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1674 - accuracy: 0.8727\n",
      "Epoch 19/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1629 - accuracy: 0.8692\n",
      "Epoch 20/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1584 - accuracy: 0.8715\n",
      "Epoch 21/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1546 - accuracy: 0.8773\n",
      "Epoch 22/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1511 - accuracy: 0.8785\n",
      "Epoch 23/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.8808\n",
      "Epoch 24/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.8820\n",
      "Epoch 25/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.1418 - accuracy: 0.8855\n",
      "Epoch 26/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.1389 - accuracy: 0.8855\n",
      "Epoch 27/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1362 - accuracy: 0.8890\n",
      "Epoch 28/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.8914\n",
      "Epoch 29/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1311 - accuracy: 0.8949\n",
      "Epoch 30/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.8984\n",
      "Epoch 31/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1263 - accuracy: 0.9007\n",
      "Epoch 32/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1239 - accuracy: 0.9042\n",
      "Epoch 33/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.1216 - accuracy: 0.9089\n",
      "Epoch 34/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.9112\n",
      "Epoch 35/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1170 - accuracy: 0.9136\n",
      "Epoch 36/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1146 - accuracy: 0.9159\n",
      "Epoch 37/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1125 - accuracy: 0.9171\n",
      "Epoch 38/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1105 - accuracy: 0.9217\n",
      "Epoch 39/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1086 - accuracy: 0.9206\n",
      "Epoch 40/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1065 - accuracy: 0.9241\n",
      "Epoch 41/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1045 - accuracy: 0.9264\n",
      "Epoch 42/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1027 - accuracy: 0.9287\n",
      "Epoch 43/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.9287\n",
      "Epoch 44/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9357\n",
      "Epoch 45/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0970 - accuracy: 0.9404\n",
      "Epoch 46/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0951 - accuracy: 0.9428\n",
      "Epoch 47/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0937 - accuracy: 0.9439\n",
      "Epoch 48/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.9439\n",
      "Epoch 49/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0901 - accuracy: 0.9474\n",
      "Epoch 50/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0884 - accuracy: 0.9498\n",
      "Epoch 51/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0868 - accuracy: 0.9498\n",
      "Epoch 52/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.9544\n",
      "Epoch 53/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.9533\n",
      "Epoch 54/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 0.9603\n",
      "Epoch 55/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9626\n",
      "Epoch 56/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0790 - accuracy: 0.9638\n",
      "Epoch 57/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9661\n",
      "Epoch 58/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.9685\n",
      "Epoch 59/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0751 - accuracy: 0.9661\n",
      "Epoch 60/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9708\n",
      "Epoch 61/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9708\n",
      "Epoch 62/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9708\n",
      "Epoch 63/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.9696\n",
      "Epoch 64/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.9720\n",
      "Epoch 65/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9708\n",
      "Epoch 66/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.9720\n",
      "Epoch 67/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.9708\n",
      "Epoch 68/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9720\n",
      "Epoch 69/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0635 - accuracy: 0.9720\n",
      "Epoch 70/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy: 0.9731\n",
      "Epoch 71/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0610 - accuracy: 0.9731\n",
      "Epoch 72/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9743\n",
      "Epoch 73/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9755\n",
      "Epoch 74/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9743\n",
      "Epoch 75/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9743\n",
      "Epoch 76/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9766\n",
      "Epoch 77/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9766\n",
      "Epoch 78/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9766\n",
      "Epoch 79/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9766\n",
      "Epoch 80/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 0.9766\n",
      "Epoch 81/100\n",
      "27/27 [==============================] - 0s 5ms/step - loss: 0.0515 - accuracy: 0.9801\n",
      "Epoch 82/100\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.9801\n",
      "Epoch 83/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0503 - accuracy: 0.9778\n",
      "Epoch 84/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9801\n",
      "Epoch 85/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0488 - accuracy: 0.9790\n",
      "Epoch 86/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0476 - accuracy: 0.9825\n",
      "Epoch 87/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9825\n",
      "Epoch 88/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0461 - accuracy: 0.9813\n",
      "Epoch 89/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.9813\n",
      "Epoch 90/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9825\n",
      "Epoch 91/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0440 - accuracy: 0.9813\n",
      "Epoch 92/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 0.9825\n",
      "Epoch 93/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9825\n",
      "Epoch 94/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0422 - accuracy: 0.9836\n",
      "Epoch 95/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9836\n",
      "Epoch 96/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 0.9825\n",
      "Epoch 97/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0402 - accuracy: 0.9848\n",
      "Epoch 98/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9836\n",
      "Epoch 99/100\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.9848\n",
      "Epoch 100/100\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b1c45da850>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "ann.fit(X_train, Y_train, batch_size = 32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.051693204790353775, 0.9720930457115173]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = ann.evaluate(X_test, Y_test, batch_size=128)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred = ann.predict(X_test)\n",
    "Y_pred = np.round_(Y_pred)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[167,   1,   1,   3],\n",
       "       [  0,   5,   0,   0],\n",
       "       [  0,   0,   5,   0],\n",
       "       [  2,   0,   0,  31]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_pred.argmax(axis=1),Y_test.argmax(axis=1))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "sns.heatmap(cm, annot=True, xticklabels=dataset.iloc[:, -8:-4].columns,\n",
    "            yticklabels=dataset.iloc[:, -8:-4].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       169\n",
      "           1       1.00      0.83      0.91         6\n",
      "           2       1.00      0.83      0.91         6\n",
      "           3       0.94      0.94      0.94        34\n",
      "\n",
      "   micro avg       0.98      0.96      0.97       215\n",
      "   macro avg       0.98      0.90      0.93       215\n",
      "weighted avg       0.98      0.96      0.97       215\n",
      " samples avg       0.96      0.96      0.96       215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Python 3.9\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.97922849, 0.90909091, 0.90909091, 0.94117647])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = f1_score(Y_test, Y_pred, average=None)\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\\dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_1\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...layers\\dense_2\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...metrics\\mean_metric_wrapper\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-01-16 16:16:52         1830\n",
      "metadata.json                                  2023-01-16 16:16:52           64\n",
      "variables.h5                                   2023-01-16 16:16:52        58344\n"
     ]
    }
   ],
   "source": [
    "pickle.dump(ann, open(\"model.pkl\",\"wb\"))\n",
    "pickle.dump(sc,open('scalar.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "390599a7e1f63e8f1c885d65702f9ad1264cb546edbfd356a254c010a94ea9c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
